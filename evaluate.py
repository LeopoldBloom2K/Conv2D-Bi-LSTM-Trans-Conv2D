import torch
import soundfile as sf
import numpy as np
import argparse
import os
import sys
import museval
from tqdm import tqdm
import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.crnn_separator import CRNN_Separator
from utils.audio_processor import AudioProcessor

def evaluate_dataset(args):
    # 1. ì„¤ì • (í•™ìŠµ ëª¨ë¸ê³¼ ë™ì¼í•˜ê²Œ ê³ ì •)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Evaluation Device: {device}")
    
    SR = 22050
    N_FFT = 1024        # í•™ìŠµ ì„¤ì •
    HOP_LENGTH = 256    # í•™ìŠµ ì„¤ì •
    N_BINS = 512        # n_fft // 2
    
    # 2. ëª¨ë¸ ë¡œë“œ
    model = CRNN_Separator(input_channels=2, n_bins=N_BINS, num_stems=4).to(device)
    checkpoint = torch.load(args.model_path, map_location=device)
    
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    model.eval()
    
    # 3. ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ
    processor = AudioProcessor(sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH)
    
    # 4. í‰ê°€í•  ê³¡ ë¦¬ìŠ¤íŠ¸ì—…
    # ì…ë ¥ëœ í´ë”ê°€ ë…¸ë˜ í´ë”ì¸ì§€, ë…¸ë˜ë“¤ì´ ë“¤ì–´ìˆëŠ” ìƒìœ„ í´ë”ì¸ì§€ í™•ì¸
    if os.path.exists(os.path.join(args.test_dir, "mixture.wav")):
        # ë‹¨ì¼ ê³¡ í´ë”ì¸ ê²½ìš°
        song_folders = [args.test_dir]
    else:
        # ìƒìœ„ í´ë”ì¸ ê²½ìš° (ëª¨ë“  í•˜ìœ„ í´ë” ê²€ìƒ‰)
        song_folders = [f.path for f in os.scandir(args.test_dir) if f.is_dir()]
    
    print(f"ì´ {len(song_folders)}ê°œì˜ ê³¡ì„ í‰ê°€í•©ë‹ˆë‹¤.")
    
    # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
    sdr_results = []
    
    # 5. ë°˜ë³µ í‰ê°€ ì‹œì‘
    for song_dir in tqdm(song_folders):
        try:
            song_name = os.path.basename(song_dir)
            mix_path = os.path.join(song_dir, "mixture.wav")
            target_path = os.path.join(song_dir, f"{args.target}.wav")
            
            if not os.path.exists(mix_path) or not os.path.exists(target_path):
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                continue

            # ì˜¤ë””ì˜¤ ë¡œë“œ (Stereo)
            mix_audio = processor.load_audio(mix_path)
            ref_audio = processor.load_audio(target_path)
            
            # --- ê¸¸ì´ ë§ì¶”ê¸° (30ì´ˆ ì œí•œ í•´ì œ ê°€ëŠ¥) ---
            # ì „ì²´ í‰ê°€ë¥¼ ìœ„í•´ 30ì´ˆ ì œí•œì„ í’€ê±°ë‚˜, ì†ë„ë¥¼ ìœ„í•´ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            # ì—¬ê¸°ì„  ì •í™•ë„ë¥¼ ìœ„í•´ ì „ì²´ ê¸¸ì´ë¥¼ ì‚¬ìš©í•˜ë˜, ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì¡°ì ˆí•˜ì„¸ìš”.
            min_len = min(mix_audio.shape[1], ref_audio.shape[1])
            
            # ë„ˆë¬´ ê¸´ ê³¡ì€ ë©”ëª¨ë¦¬ í„°ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ìµœëŒ€ 1ë¶„(60ì´ˆ)ê¹Œì§€ë§Œ í‰ê°€ (ì˜µì…˜)
            # max_samples = 60 * SR
            # min_len = min(min_len, max_samples)

            mix_audio = mix_audio[:, :min_len]
            ref_audio = ref_audio[:, :min_len]

            # STFT ë° ì¶”ë¡ 
            mix_mag, mix_phase = processor.audio_to_stft(mix_audio)
            mix_mag_tensor = mix_mag.unsqueeze(0).to(device)

            with torch.no_grad():
                masks = model(mix_mag_tensor)
                masks = masks.squeeze(0).cpu().numpy() # (4, 2, Freq, Time)

            # íƒ€ê²Ÿ ë§ˆìŠ¤í¬ ê°€ì ¸ì˜¤ê¸°
            stem_indices = {'vocals': 0, 'drums': 1, 'bass': 2, 'other': 3}
            target_idx = stem_indices.get(args.target, 0)
            mask = masks[target_idx]

            # ë³µì›
            est_mag = mix_mag.cpu().numpy() * mask
            est_audio = processor.stft_to_audio(est_mag, mix_phase)

            # SDR ê³„ì‚° ì¤€ë¹„
            # (Channels, Samples) -> (n_src, Samples, Channels)
            ref = ref_audio.T[None, :, :]
            est = est_audio.T[None, :, :]
            
            # ê¸¸ì´ ë¯¸ì„¸ ì¡°ì •
            L = min(ref.shape[1], est.shape[1])
            ref = ref[:, :L, :]
            est = est[:, :L, :]

            # Museval í‰ê°€
            # win=L ë¡œ ì„¤ì •í•˜ì—¬ ê³¡ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ìœˆë„ìš°ë¡œ ê³„ì‚° (Global SDR)
            sdr, _, _, _ = museval.evaluate(ref, est, win=L, hop=L)
            
            # NaN ê°’ ì œê±° í›„ ì¤‘ê°„ê°’ ì‚¬ìš©
            score = np.nanmedian(sdr)
            sdr_results.append({'song': song_name, 'sdr': score})
            
        except Exception as e:
            print(f"Error evaluating {song_name}: {e}")
            continue

    # 6. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    if not sdr_results:
        print("í‰ê°€ëœ ê³¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # DataFrameìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬
    df = pd.DataFrame(sdr_results)
    mean_sdr = df['sdr'].mean()
    median_sdr = df['sdr'].median()
    
    print("\n" + "="*40)
    print(f"ğŸ“Š í‰ê°€ ì™„ë£Œ: {args.target}")
    print(f"   - ì „ì²´ ê³¡ ìˆ˜: {len(df)}")
    print(f"   - í‰ê·  SDR: {mean_sdr:.4f} dB")
    print(f"   - ì¤‘ì•™ê°’ SDR: {median_sdr:.4f} dB")
    print("="*40)
    
    # CSV ì €ì¥ (ì„ íƒ)
    df.to_csv(f"eval_results_{args.target}.csv", index=False)
    print(f"ìƒì„¸ ê²°ê³¼ ì €ì¥ë¨: eval_results_{args.target}.csv")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    # í´ë” ê²½ë¡œ ì…ë ¥ (test í´ë” í†µì§¸ë¡œ ë„£ì–´ë„ ë¨)
    parser.add_argument('--test_dir', type=str, required=True, help='Path to test dataset folder')
    parser.add_argument('--target', type=str, default='vocals', help='Target name (vocals, drums, bass, other)')
    parser.add_argument('--model_path', type=str, required=True, help='Model checkpoint path')
    
    args = parser.parse_args()
    evaluate_dataset(args)