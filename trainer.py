import torch
import torch.nn as nn
import torch.optim as optim
from torch.amp import autocast, GradScaler
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import os
import numpy as np

# utils í´ë”ì— EarlyStoppingì´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
# ë§Œì•½ ì—†ë‹¤ë©´ ì´ ì¤„ì„ ì§€ìš°ê³  fit í•¨ìˆ˜ ë‚´ë¶€ì˜ ê´€ë ¨ ì½”ë“œë¥¼ ì£¼ì„ ì²˜ë¦¬í•˜ì„¸ìš”.
from utils.early_stopping import EarlyStopping

class Trainer:
    def __init__(self, model, train_loader, val_loader, args):
        self.args = args
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        
        # 1. ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ìš°ì„ )
        self.use_cuda = torch.cuda.is_available()
        self.device = torch.device('cuda' if self.use_cuda else 'cpu')
        self.model = self.model.to(self.device)
        
        # 2. ìµœì í™” ë„êµ¬ (Adam)
        self.optimizer = optim.Adam(self.model.parameters(), lr=args.lr, weight_decay=1e-5)
        
        # 3. ì†ì‹¤ í•¨ìˆ˜ (L1 Lossê°€ ìŒì› ë¶„ë¦¬ì— ì¢‹ìŒ)
        self.criterion = nn.L1Loss()
        
        # 4. í˜¼í•© ì •ë°€ë„ í•™ìŠµ (ë©”ëª¨ë¦¬ ì ˆì•½ & ì†ë„ í–¥ìƒ)
        self.scaler = GradScaler('cuda', enabled=self.use_cuda)
        
        # 5. ë¡œê¹… ë° ì €ì¥
        self.writer = SummaryWriter(log_dir=f"runs/{args.exp_name}")
        self.best_model_path = os.path.join(args.checkpoint_dir, f'{args.exp_name}_best.pth')
        
        # Early Stopping (25ë²ˆ ë™ì•ˆ ì„±ëŠ¥ í–¥ìƒ ì—†ìœ¼ë©´ ì¤‘ë‹¨)
        patience_val = getattr(args, 'patience', 25) # argsì— ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 25
        self.early_stopping = EarlyStopping(patience=patience_val, verbose=True, path=self.best_model_path)

    def train_epoch(self, epoch):
        self.model.train()
        train_loss = 0
        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch+1}/{self.args.epochs} [Train]")
        
        for mix, targets in pbar:
            # mix: (Batch, 2, Freq, Time)
            # targets: (Batch, 4, 2, Freq, Time)
            mix, targets = mix.to(self.device), targets.to(self.device)
            self.optimizer.zero_grad()
            
            # Mixed Precision
            with autocast(device_type='cuda', enabled=self.use_cuda):
                # 1. ëª¨ë¸ì´ ë§ˆìŠ¤í¬ ì˜ˆì¸¡ (Batch, 4, 2, Freq, Time)
                masks = self.model(mix)
                
                # 2. ë§ˆìŠ¤í¬ë¥¼ ë¯¹ìŠ¤ì— ì ìš©
                # mixëŠ” (Batch, 2, ...) ì´ë¯€ë¡œ (Batch, 1, 2, ...)ë¡œ ì°¨ì›ì„ ëŠ˜ë ¤ì•¼
                # (Batch, 4, 2, ...)ì¸ ë§ˆìŠ¤í¬ì™€ ê³±í•´ì§ (Broadcasting)
                mix_expanded = mix.unsqueeze(1) 
                estimated_sources = mix_expanded * masks
                
                # 3. ì •ë‹µ(targets)ê³¼ ë¹„êµí•˜ì—¬ ì†ì‹¤ ê³„ì‚°
                loss = self.criterion(estimated_sources, targets)
            
            # ì—­ì „íŒŒ (Backpropagation)
            self.scaler.scale(loss).backward()
            self.scaler.step(self.optimizer)
            self.scaler.update()
            
            train_loss += loss.item()
            pbar.set_postfix({'loss': f"{loss.item():.4f}"})
            
        return train_loss / len(self.train_loader)

    def validate(self):
        self.model.eval()
        val_loss = 0
        with torch.no_grad():
            for mix, targets in self.val_loader:
                mix, targets = mix.to(self.device), targets.to(self.device)
                
                with autocast(device_type='cuda', enabled=self.use_cuda):
                    masks = self.model(mix)
                    mix_expanded = mix.unsqueeze(1)
                    estimated_sources = mix_expanded * masks
                    
                    # ê²€ì¦ ì†ì‹¤ ê³„ì‚°
                    loss = self.criterion(estimated_sources, targets)
                    
                val_loss += loss.item()
        return val_loss / len(self.val_loader)

    def fit(self):
        print(f"ğŸš€ í•™ìŠµ ì‹œì‘! (Device: {self.device})")
        print(f"ğŸ¯ ëª©í‘œ: 4ê°œ ì•…ê¸° ë™ì‹œ ë¶„ë¦¬ (Vocals, Drums, Bass, Other)")
        
        for epoch in range(self.args.epochs):
            # 1. í›ˆë ¨
            train_loss = self.train_epoch(epoch)
            
            # 2. ê²€ì¦
            val_loss = self.validate()
            
            print(f"Epoch {epoch+1}: Train Loss {train_loss:.5f} | Val Loss {val_loss:.5f}")
            self.writer.add_scalar('Loss/train', train_loss, epoch)
            self.writer.add_scalar('Loss/val', val_loss, epoch)

            # 3. ì¡°ê¸° ì¢…ë£Œ ë° ëª¨ë¸ ì €ì¥ ì²´í¬
            self.early_stopping(val_loss, self.model)
            if self.early_stopping.early_stop:
                print("ğŸ›‘ Early Stopping ë°œë™! í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
        
        self.writer.close()
        print(f"âœ¨ í•™ìŠµ ì™„ë£Œ. ìµœì  ëª¨ë¸ ì €ì¥ë¨: {self.best_model_path}")