import torch
from torch.utils.data import DataLoader
import os
import datetime

from options import get_args
from trainer import Trainer
from models.crnn_separator import CRNN_Separator
from utils.audio_processor import AudioProcessor
from utils.dataset import RemixingDataset

def main():
    start_time = datetime.datetime.now()
    timestamp = start_time.strftime('%Y%m%d_%H%M%S')
    
    print("="*40)
    print(f"â° í•™ìŠµ ì‹œì‘: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*40)

    args = get_args()
    args.exp_name = f"{args.exp_name}_{timestamp}"
    
    print(f"ğŸ“ ì‹¤í—˜ ì´ë¦„: {args.exp_name}")
    print(f"âš™ï¸ ëª¨ë¸ ì„¤ì •: Hidden={args.hidden_size}, Layers={args.num_layers}")
    
    # ì²´í¬í¬ì¸íŠ¸ í´ë” ìƒì„± (í•„ìˆ˜)
    os.makedirs(args.checkpoint_dir, exist_ok=True)
    
    processor = AudioProcessor(sr=args.sr, n_fft=args.n_fft, hop_length=args.hop_length)
    
    train_dataset = RemixingDataset(args.train_dir, processor, duration=3.0, remix_prob=0.5)
    val_dataset = RemixingDataset(args.val_dir, processor, duration=3.0, remix_prob=0.0)
    
    train_loader = DataLoader(
        train_dataset, batch_size=args.batch_size, shuffle=True, 
        num_workers=4, pin_memory=True, persistent_workers=True
    )
    val_loader = DataLoader(
        val_dataset, batch_size=args.batch_size, shuffle=False, 
        num_workers=4, pin_memory=True, persistent_workers=True
    )
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # [ìˆ˜ì •] ì˜µì…˜ê°’ ì „ë‹¬í•˜ì—¬ ëª¨ë¸ ìƒì„±
    model = CRNN_Separator(
        input_channels=2, 
        n_bins=args.n_fft // 2, 
        num_stems=4,
        hidden_size=args.hidden_size, # ì˜µì…˜ ì ìš©
        num_layers=args.num_layers    # ì˜µì…˜ ì ìš©
    ).to(device)
    
    if args.pretrained_path and os.path.exists(args.pretrained_path):
        print(f"â™»ï¸ Fine-tuning: {args.pretrained_path}")
        try:
            checkpoint = torch.load(args.pretrained_path)
            state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
            model.load_state_dict(state_dict, strict=False)
            print("   -> ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"   -> ë¡œë“œ ì‹¤íŒ¨: {e}")

    trainer = Trainer(model, train_loader, val_loader, args)
    trainer.fit()

    end_time = datetime.datetime.now()
    print(f"â³ ì†Œìš” ì‹œê°„: {end_time - start_time}")

if __name__ == '__main__':
    main()