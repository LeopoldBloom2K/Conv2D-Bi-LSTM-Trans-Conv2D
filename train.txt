crnn_long_20251225_041902_best.pth / hidden_size 256 num_layers 3 SDR 3.20 dB

crnn_large_finetune_20251226_231234_best / hidden_size 512 num_layers 4 SDR UNKNOWN
crnn_large_finetune_ver1_20251227_171118_best / hidden_size 512 num_layers 4 SDR 3.7966 dB (1.2, 0.0)
crnn_large_final_tune_20251228_063127_best / hidden_size 512 num_layers 4 batch_size 8 lr 0.0001 3.9331 dB


// section 1. model merging, testing
두 모델을 합침 <merge_models.py> 평균 SDR: 3.9631 dB crnn_large_merged_3.96.pth

에폭 5를 시도해 두 모델 통합 테스트 진행 

crnn_large_ultimate_4db_20251228_195447_best.pth / hidden_size 512 num_layers 4 batch_size 8 lr 0.00005 crnn_large_merged_3.96.pth 2.0048 dB

위 모델의 기능이 온전히 발현되지않아 다음과 같은 시도를 함 
- 소프트 마스트 --mask_scale 0.8 2.2692
- 노이즈 허용 --threshold 0.05 1.5643
- 강력한 압착 --mask_scale 1.5

전과 다른 양상을 띄지 않아 random_prob를 비활성화 후 낮은 에폭으로 시도함

crnn_large_final_fix_20251228_233017_best / hidden_size 512 num_layers 4 batch_size 8 lr 0.00001 epochs 5 crnn_large_ultimate_4db_20251228_195447_best.pth 2.0953 dB

가중치 블렌딩 (Weight Blending) 으로 3.93dB와 merge한 모델을 블렌딩함 
merged_dict[key] = (state_dict1[key] * 0.8) + (state_dict2[key] * 0.2)
state_dict1 = crnn_large_final_tune_20251228_063127_best
state_dict2 = crnn_large_ultimate_4db_20251228_195447_best
merged_dict = crnn_large_merged_0.8_0.2 // 2.8281 dB (1.1, 0.1)

통과한 모델의 부산물이 작게 내보낼 가능성이 보여 출력 gain 보정 (Output Gain Correction) 수행함

테스트 A (출력 강화): --mask_scale 2.0 --threshold 0.1
테스트 B (극단적 강화): --mask_scale 3.5 --threshold 0.1
테스트 C (반대로 축소): --mask_scale 0.5 --threshold 0.1

수행 전 자동으로 gain 값 자동 추적 코드를 수행함. // Gain Correction: x3.1 평균 SDR: 2.2213 dB

gain 3.1 배수에도 큰 차이가 없어 입력 데이터의 규격 (N_FFT, SR)의 문제라고 추정함.
가중치 블렌딩 재수행하되 merged_dict[key] = (state_dict1[key] * 0.9) + (state_dict2[key] * 0.1) 적용, 내부 변수 모두 상수화함 SR = 22050 N_FFT = 1024 HOP_LENGTH = 256 N_BINS = 512

// section 2. Model Rollback & Retraining Strategy

SDR 점수의 평균이 좋아지지않아 루트 모델로 다시 회귀함. (crnn_large_finetune_20251226_231234_best 이후 finetune 함) <- 데이터의 신호처리 로직을 학습해 과적합 발생함
dataset.py의 데이터 증강 코드 (random_prob)를 다시 활성화하였고, 재학습 시도함.

gemini.ai 결과 --
이미지의 그래프는 모델이 학습 데이터에 대해 얼마나 어려워하는지(Loss)를 보여줍니다.
주황색 선 (맨 아래, ultimate...):
상태: Loss가 0에 가깝게 급격히 떨어졌습니다.
의미: 이것은 "과적합(Overfitting)" 혹은 **"암기"**입니다. 데이터 증강(Augmentation) 없이 똑같은 문제만 계속 풀다 보니, 모델이 답을 외워버린 상태입니다. 실전(Test)에서 SDR이 2.0dB로 폭락한 이유가 바로 이 때문입니다.
노란색/초록색 선 (중간, final_tune...):
상태: 적당한 Loss를 유지하며 완만하게 떨어지고 있습니다.
의미: 가장 건강한 상태입니다. (사용자님이 남기라고 한 그 모델입니다.) 이 상태에서 **"데이터 증강"**이라는 새로운 자극을 주어 성능을 끌어올려야 합니다.

재학습 전략 -- 
1. 매 에폭마다 새로운 조합의 학습 발생 (dataset.py 증강코드 복원)
2. 이전 3.98 dB를 기록한 모델을 가져와 다시 학습함 (pretrained), lr 조정 (0.0001), --batch_size 8 or 16 (기존 8), --argumentation 강도 (remix_prob = 0.5)
3. target stem 되어진 data 외에 모두 silence 처리하여 반주 학습 (보컬 무음)으로 보컬의 선명도를 증가하게함.

결과 -- 
inference.py 로 결과물을 실제로 접한 결과, 모든 stem 되어진 음원들이 노이즈가 섞이거나 소리가 매우 작아 SDR 점수를 매길 필요 없이 폐기처분이 확실시 됨.
모델 (crnn_large_final_tune_20251228_063127_best) 폐기

// section 3. 이전 모델 호출 및 stem 객체 명시 후 재학습 시도
1. train.py 에서 학습(train) / 검증 (val) 데이터셋 접근시 target_stem 인지를 활용해 오인학습하지 않도록 호출부를 수정함.
2. layer_freezing 기능을 도입해 기존 레이어를 얼리고 출력 레이어만 학습하여 취약한 부분에 초점을 맞출 예정. 1번 방법 무효할 시 시도함. 

결과 -- 
학습 완료된 모델 SDR 측정 결과 음수대로 나와서 원본 모델의 SDR 점수를 다시 측정, 3.78 dB의 기존 점수를 보여 학습이 잘못된 것으로 추정함.

dataset 에서 오인학습을 방지하기 위한 호출부 부분에서 stem 인덱스 (bass, drums, other, vocals)에 해당하지않는 데이터 예외값을 if-else 값을 수정함. (train.py 실행 시 존재하지 않는 파일을 출력함.)

조치 후 결과 --
SDR 점수가 음수로 측정되어 데이터가 제대로 로드되었는지 확인함 (check_data), 
데이터 중 일부가 numpy array를 필요로 해 로드 실패가 일어남 형변환 로직 추가
안전 로딩 이슈로 인해 fake_stereo 기능을 넣어 데이터 전처리 예외 처리함 
차원이 짝수로 통일을 위해 하드코딩함 (513 -> 512)

eval_result_vocals에서 대부분의 음원 SDR 점수가 음수로 나타남
데이터의 입력규격 오류와 기존 학습과의 차이를 확인함

데이터를 모델에 넣기 전부터 log로 변환 후 입력 np.abs(librosa.stft(...)) -> mag_numpy = np.log1p(mag_numpy)

로그 변환 후 정규화 로직을 추가하여 다듬었음.

+ 학습-평가 자동화 코드를 적용해 최대 55번을 적용한 결과 -0.5~-2.0dB를 유지해 모델 구조 개선 필요.

// section 4. 모델 개선 후 재학습 (non-pretrained)

기존 문제가 된 Decoder(TransConv2D)에서 사라진 디테일을 압축 해제하는 과정에서 손실된 부분을 생성하는 데에 한계를 직면함. (LSTM 구조 한계)
이를 U-Net 구조로 보완하여 원본의 디테일을 참고하여 재배열함.
standard CRNN -> U-net CRNN

(수정 26.01.15) 

직전 수정본은 단순히 해당 음원에서 BPM 의 위치를 원본 음원과 비교하여 위치 정보를 참고해 다시 재배열하는 U-net 구조를 계획했지만, 
장르의 다양성에 대한 BPM 혼동할 수 있었고, 
loss 값 측정시 오답일 경우 즉시 정답이 아님으로 학습되어 직전 모델에서 무음으로 판별된 사례와 연결이 됨,
또한 hidden_size를 512 -> 0/1 으로 바로 압축하여 손실이 매우 컸음,

(최종 수정 정리)
| 구분 | 기존 모델 (Current) | 추천 모델 (Multi-Task U-Net) |
| 핵심 구조 | Encoder → LSTM → Decoder | Encoder → LSTM → [Decoder] + [Rhythm Head] |
| 분석 | 악기별 | 악기별 & 박자별 |
| Rhythm Head | 없음 | Linear → LayerNorm → Dropout(0.4) → Linear (깔때기 구조) |
| 규격 | Hidden 512 / Layer 4 | Hidden 512 / Layer 4 (기존 규격 유지) |
| loss | BCE loss | Focal loss |
| optimizer (weight decay) | Adam (1e-5) | AdamW (1e-3) |


python train.py ^
    --train_dir "data\train" ^
    --val_dir "data\val" ^
    --exp_name "crnn_large_final_tune" ^
    --hidden_size 512 ^
    --num_layers 4 ^
    --batch_size 8 ^
    --pretrained_path "checkpoints\crnn_large_finetune_ver1_20251227_171118_best.pth" ^
    --lr 0.0001

python train.py ^
    --train_dir "data\train" ^
    --val_dir "data\val" ^
    --exp_name "crnn_large_final_fix" ^
    --hidden_size 512 ^
    --num_layers 4 ^
    --batch_size 8 ^
    --lr 0.00001 ^
    --pretrained_path "checkpoints\crnn_large_ultimate_4db_20251228_195447_best.pth" ^
    --epochs 5

python evaluate.py ^
    --test_dir "data\val" ^
    --model_path "checkpoints\Finetune_crnn_large_retrain_augmentation_20260105_192501_best.pth" ^
    --hidden_size 512 ^
    --num_layers 4 ^
    --mask_scale 1.0 ^
    --threshold 0.0

python evaluate.py ^
    --test_dir "data\val" ^
    --model_path "checkpoints\Finetune_Retrain_with_Augmentation_20260106_114554_best.pth" ^
    --hidden_size 512 ^
    --num_layers 4 ^



python train.py ^
    --train_dir "data\train" ^
    --val_dir "data\val" ^
    --exp_name "Retrain_with_Augmentation" ^
    --hidden_size 512 ^
    --num_layers 4 ^
    --batch_size 8 ^
    --lr 0.0001 ^
    --pretrained_path "checkpoints\crnn_large_finetune_ver1_20251227_171118_best.pth" ^
    --epochs 200