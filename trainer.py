import torch
import torch.nn as nn
import torch.optim as optim
from torch.amp import autocast, GradScaler
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import os
import numpy as np

# utils í´ë”ì— EarlyStoppingì´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
from utils.early_stopping import EarlyStopping

class Trainer:
    def __init__(self, model, train_loader, val_loader, args):
        self.args = args
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        
        # 1. ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.use_cuda = torch.cuda.is_available()
        self.device = torch.device('cuda' if self.use_cuda else 'cpu')
        self.model = self.model.to(self.device)
        
        # 2. ìµœì í™” ë„êµ¬
        self.optimizer = optim.Adam(self.model.parameters(), lr=args.lr, weight_decay=1e-5)
        
        # 3. ì†ì‹¤ í•¨ìˆ˜
        self.criterion = nn.L1Loss()
        
        # 4. í˜¼í•© ì •ë°€ë„ í•™ìŠµ
        self.scaler = GradScaler('cuda', enabled=self.use_cuda)
        
        # 5. ë¡œê¹… ë° ì €ì¥ [ìˆ˜ì •ë¨: ì—ëŸ¬ ë°©ì§€ìš© ì•ˆì „ ì½”ë“œ]
        # ìœˆë„ìš° ê²½ë¡œ í˜¸í™˜ì„±ì„ ìœ„í•´ os.path.join ì‚¬ìš©
        log_dir = os.path.join("runs", args.exp_name)
        # í´ë”ê°€ ì—†ìœ¼ë©´ ë¯¸ë¦¬ ìƒì„± (Tensorboard ì—ëŸ¬ ë°©ì§€)
        os.makedirs(log_dir, exist_ok=True)
        
        self.writer = SummaryWriter(log_dir=log_dir)
        self.best_model_path = os.path.join(args.checkpoint_dir, f'{args.exp_name}_best.pth')
        
        # Early Stopping
        patience_val = getattr(args, 'patience', 25)
        self.best_score = None 
        # (Trainer ë‚´ë¶€ì—ì„œë§Œ ì“¸ ê°„ë‹¨í•œ ë³€ìˆ˜, í˜¹ì€ utils.EarlyStopping ì‚¬ìš©)
        self.early_stopping = EarlyStopping(patience=patience_val, verbose=True, path=self.best_model_path)

    def train_epoch(self, epoch):
        self.model.train()
        train_loss = 0
        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch+1}/{self.args.epochs} [Train]")
        
        for mix, targets in pbar:
            mix, targets = mix.to(self.device), targets.to(self.device)
            self.optimizer.zero_grad()
            
            with autocast(device_type='cuda', enabled=self.use_cuda):
                masks = self.model(mix)
                mix_expanded = mix.unsqueeze(1) 
                estimated_sources = mix_expanded * masks
                loss = self.criterion(estimated_sources, targets)
            
            self.scaler.scale(loss).backward()
            self.scaler.step(self.optimizer)
            self.scaler.update()
            
            train_loss += loss.item()
            pbar.set_postfix({'loss': f"{loss.item():.4f}"})
            
        return train_loss / len(self.train_loader)

    def validate(self):
        self.model.eval()
        val_loss = 0
        with torch.no_grad():
            for mix, targets in self.val_loader:
                mix, targets = mix.to(self.device), targets.to(self.device)
                
                with autocast(device_type='cuda', enabled=self.use_cuda):
                    masks = self.model(mix)
                    mix_expanded = mix.unsqueeze(1)
                    estimated_sources = mix_expanded * masks
                    loss = self.criterion(estimated_sources, targets)
                    
                val_loss += loss.item()
        return val_loss / len(self.val_loader)

    def fit(self):
        print(f"ğŸš€ í•™ìŠµ ì‹œì‘! (Device: {self.device})")
        print(f"ğŸ¯ ëª©í‘œ: 4ê°œ ì•…ê¸° ë™ì‹œ ë¶„ë¦¬")
        
        for epoch in range(self.args.epochs):
            train_loss = self.train_epoch(epoch)
            val_loss = self.validate()
            
            print(f"Epoch {epoch+1}: Train Loss {train_loss:.5f} | Val Loss {val_loss:.5f}")
            self.writer.add_scalar('Loss/train', train_loss, epoch)
            self.writer.add_scalar('Loss/val', val_loss, epoch)

            self.early_stopping(val_loss, self.model)
            if self.early_stopping.early_stop:
                print("ğŸ›‘ Early Stopping ë°œë™! í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
        
        self.writer.close()
        print(f"âœ¨ í•™ìŠµ ì™„ë£Œ. ìµœì  ëª¨ë¸ ì €ì¥ë¨: {self.best_model_path}")