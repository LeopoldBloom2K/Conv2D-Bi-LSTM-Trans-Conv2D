import torch
import numpy as np
import museval
import os
import sys
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.crnn_separator import CRNN_Separator
from utils.audio_processor import AudioProcessor

def find_optimal_gain():
    # 1. ì²´í¬í¬ì¸íŠ¸ ê·œê²©ì— ë§ê²Œ ê°•ì œ ì„¤ì • (ì—ëŸ¬ í•´ê²° í•µì‹¬)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    SR = 22050      # ì²´í¬í¬ì¸íŠ¸ í•™ìŠµ ì‚¬ì–‘
    N_FFT = 1024    # ì²´í¬í¬ì¸íŠ¸ í•™ìŠµ ì‚¬ì–‘
    HOP_LENGTH = 256
    N_BINS = 512    # 8192 ì‚¬ì´ì¦ˆ ë¶ˆì¼ì¹˜ í•´ê²°ì„ ìœ„í•œ ê³ ì •ê°’
    HIDDEN_SIZE = 512
    NUM_LAYERS = 4
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì ê²½ë¡œ)
    model_path = r"checkpoints\crnn_large_merged_0.9_0.1.pth" 
    test_dir = r"data\val"
    
    print(f"ğŸš€ ìµœì  Gain íƒìƒ‰ ì‹œì‘ (êµ¬ì¡° ê³ ì •: n_bins=512, hidden=512)")
    
    # 2. ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ë° ëª¨ë¸ ì´ˆê¸°í™”
    processor = AudioProcessor(sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH)
    model = CRNN_Separator(
        input_channels=2, 
        n_bins=N_BINS, 
        num_stems=4,
        hidden_size=HIDDEN_SIZE, 
        num_layers=NUM_LAYERS
    ).to(device)

    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    checkpoint = torch.load(model_path, map_location=device)
    state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
    model.load_state_dict(state_dict)
    model.eval()

    # 3. ë°ì´í„° ë¡œë“œ
    song_folders = [f.path for f in os.scandir(test_dir) if f.is_dir()]
    if not song_folders:
        print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    song_dir = song_folders[0]
    print(f"ğŸµ ë¶„ì„ ëŒ€ìƒ: {os.path.basename(song_dir)}")
    
    mix_audio = processor.load_audio(os.path.join(song_dir, "mixture.wav"))
    ref_audio = processor.load_audio(os.path.join(song_dir, "vocals.wav"))
    
    min_len = min(mix_audio.shape[1], ref_audio.shape[1])
    mix_mag, mix_phase = processor.audio_to_stft(mix_audio[:, :min_len])
    
    with torch.no_grad():
        masks = model(mix_mag.unsqueeze(0).to(device))
        raw_mask = masks.squeeze(0).cpu().numpy()[0] 

    # 4. Gain íƒìƒ‰ (0.5 ~ 8.0)
    gain_candidates = np.arange(0.5, 8.1, 0.2)
    best_sdr = -float('inf')
    best_gain = 1.0
    
    for gain in tqdm(gain_candidates, desc="SDR ìµœì í™” ì¤‘"):
        adjusted_mask = np.clip(raw_mask * gain, 0, 1)
        est_mag = mix_mag.numpy() * adjusted_mask
        est_audio = processor.stft_to_audio(est_mag, mix_phase)
        
        ref = ref_audio[:, :min_len].numpy().T[None, :, :]
        est = est_audio.T[None, :, :]
        
        sdr, _, _, _ = museval.evaluate(ref, est, win=min_len, hop=min_len)
        current_sdr = np.nanmedian(sdr)
        
        if current_sdr > best_sdr:
            best_sdr = current_sdr
            best_gain = gain

    print("\n" + "="*50)
    print(f"ğŸ† ìµœì  Gain ê²°ê³¼: {best_gain:.1f}")
    print(f"ğŸ“ˆ ì˜ˆìƒ ìµœê³  SDR: {best_sdr:.4f} dB")
    print("="*50)
    print(f"ğŸ’¡ ì´ì œ evaluate.py ì‹¤í–‰ ì‹œ --gain {best_gain:.1f} ë¥¼ ì ìš©í•˜ì„¸ìš”.")

if __name__ == '__main__':
    find_optimal_gain()