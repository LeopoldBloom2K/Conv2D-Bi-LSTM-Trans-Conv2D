import torch
import soundfile as sf
import numpy as np
import argparse
import os
import museval
from torch.amp import autocast
from models.crnn_separator import CRNN_Separator
from utils.audio_processor import AudioProcessor

def evaluate_song(args):
    # 1. ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Evaluation Device: {device}")
    
    # 2. ëª¨ë¸ ë¡œë“œ (n_bins=512 í•„ìˆ˜)
    model = CRNN_Separator(n_bins=512).to(device)
    checkpoint = torch.load(args.model_path, map_location=device)
    
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    model.eval()
    
    # 3. ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ
    processor = AudioProcessor(sr=22050, n_fft=1024, hop_length=256)
    
    # 4. íŒŒì¼ ê²½ë¡œ í™•ì¸
    # args.song_dir ì˜ˆ: "D:\musdb18hq\test\Signe - My Song"
    mix_path = os.path.join(args.song_dir, "mixture.wav")
    target_path = os.path.join(args.song_dir, f"{args.target}.wav")
    
    if not os.path.exists(mix_path) or not os.path.exists(target_path):
        print("âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # 5. ì˜¤ë””ì˜¤ ë¡œë“œ
    print(f"Loading: {args.song_dir}")
    mix_audio = processor.load_audio(mix_path)
    ref_audio = processor.load_audio(target_path) # ì •ë‹µ(Reference)
    
    # --- ì¶”ë¡  (Chunking ì—†ì´ í†µìœ¼ë¡œ í•˜ê±°ë‚˜, ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ Chunking ì ìš© í•„ìš”) ---
    # í‰ê°€ì˜ ì •í™•ë„ë¥¼ ìœ„í•´ ì—¬ê¸°ì„œëŠ” í†µìœ¼ë¡œ ì²˜ë¦¬í•˜ë˜, ë©”ëª¨ë¦¬ ê´€ë¦¬ ì£¼ì˜
    # (ê¸´ ê³¡ì€ inference.pyì˜ ì²­í¬ ë¡œì§ì„ ê°€ì ¸ì™€ì•¼ í•¨. ì—¬ê¸°ì„  30ì´ˆë§Œ ì˜ë¼ì„œ í…ŒìŠ¤íŠ¸ ì¶”ì²œ)
    
    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì•ë¶€ë¶„ 30ì´ˆë§Œ ì˜ë¼ì„œ í‰ê°€ (ì†ë„ UP)
    # ì „ì²´ ê³¡ í‰ê°€ë¥¼ ì›í•˜ë©´ ì´ ë¶€ë¶„ ìŠ¬ë¼ì´ì‹±([: ...])ì„ ì œê±°í•˜ì„¸ìš”.
    test_len = min(len(mix_audio), 30 * processor.sr) 
    mix_audio = mix_audio[:test_len]
    ref_audio = ref_audio[:test_len]

    # STFT
    mix_mag, mix_phase = processor.audio_to_stft(mix_audio)
    mix_mag_tensor = mix_mag.unsqueeze(0).to(device)

    with torch.no_grad():
        with autocast(device_type='cuda'):
            mask = model(mix_mag_tensor)
            pred_mag = mix_mag_tensor * mask
            
    # ë³µì› (Estimate)
    est_audio = processor.stft_to_audio(pred_mag, mix_phase)
    
    # 6. ê¸¸ì´ ë§ì¶”ê¸° (musevalì€ ê¸¸ì´ê°€ 1ìƒ˜í”Œì´ë¼ë„ ë‹¤ë¥´ë©´ ì—ëŸ¬ë‚¨)
    min_len = min(len(ref_audio), len(est_audio))
    ref_audio = ref_audio[:min_len]
    est_audio = est_audio[:min_len]
    
    # 7. SDR ê³„ì‚°
    print("Calculating SDR Score...")
    
    # museval ì…ë ¥ í˜•íƒœ: (nsrc, samples, channels)
    # ìš°ë¦¬ëŠ” Monoì´ë¯€ë¡œ (1, samples, 1)ë¡œ ë³€í™˜
    references = ref_audio[None, :, None] 
    estimates = est_audio[None, :, None] 
    
    # win=ìƒ˜í”Œìˆ˜ (ê³¡ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ìœˆë„ìš°ë¡œ í‰ê°€)
    sdr, isr, sir, sar = museval.evaluate(references, estimates, win=min_len, hop=min_len)
    
    sdr_score = np.nanmedian(sdr)
    print("------------------------------------------------")
    print(f"ğŸµ Target Instrument: {args.target}")
    print(f"ğŸ“ˆ SDR Score: {sdr_score:.4f} dB")
    print("------------------------------------------------")
    
    # 8. ê²°ê³¼ ì €ì¥ (ë“¤ì–´ë³´ê¸° ìœ„í•´)
    out_path = "eval_result.wav"
    sf.write(out_path, est_audio, processor.sr)
    print(f"ğŸ”Š ë¶„ë¦¬ëœ íŒŒì¼ ì €ì¥ë¨: {out_path} (ë“¤ì–´ë³´ì„¸ìš”!)")

    return sdr_score

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--song_dir', type=str, required=True, help='Path to a test song folder')
    parser.add_argument('--target', type=str, default='vocals')
    parser.add_argument('--model_path', type=str, default='./checkpoints/best_model.pth')
    
    args = parser.parse_args()
    evaluate_song(args)