import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torch.amp import autocast, GradScaler 
import os
import argparse
from tqdm import tqdm

from models.crnn_separator import CRNN_Separator
from utils.audio_processor import AudioProcessor
from utils.dataset import RemixingDataset
from utils.early_stopping import EarlyStopping

def train(args):
    # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬
    use_cuda = torch.cuda.is_available()
    device = torch.device('cuda' if use_cuda else 'cpu')
    print(f"Device: {device}")
    
    if not use_cuda:
        print("âš ï¸ ì£¼ì˜: GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    os.makedirs(args.checkpoint_dir, exist_ok=True)
    best_model_path = os.path.join(args.checkpoint_dir, 'best_model.pth')

    # í”„ë¡œì„¸ì„œ ë° ë°ì´í„°ì…‹ (SR 22050, 1024 FFT ì ìš©)
    processor = AudioProcessor(sr=22050, n_fft=1024, hop_length=256)
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    full_dataset = RemixingDataset(
        args.data_dir, 
        processor, 
        target_name=args.target,
        duration=3.0,
        remix_prob=0.5
    )
    
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)
    
    model = CRNN_Separator(n_bins=512).to(device)
    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)
    criterion = nn.L1Loss()
    
    # Scaler ì´ˆê¸°í™” ì‹œ 'cuda' ëª…ì‹œ ë° GPU ì—†ì„ ë• ë„ê¸°
    scaler = GradScaler('cuda', enabled=use_cuda)

    early_stopping = EarlyStopping(patience=15, verbose=True, path=best_model_path)

    print(f"Start training... (Total: {len(full_dataset)} songs)")

    for epoch in range(args.epochs):
        # --- [Phase 1] Train ---
        model.train()
        train_loss = 0
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{args.epochs} [Train]")
        
        for mix, target in pbar:
            mix, target = mix.to(device), target.to(device)
            
            optimizer.zero_grad()
            
            # [ìˆ˜ì • 3] autocast ìµœì‹  ë¬¸ë²• ì ìš©
            with autocast(device_type='cuda', enabled=use_cuda):
                mask = model(mix)
                pred = mix * mask
                loss = criterion(pred, target)
            
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            train_loss += loss.item()
            pbar.set_postfix({'loss': loss.item()})
            
        avg_train_loss = train_loss / len(train_loader)

        # --- [Phase 2] Validation ---
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for mix, target in val_loader:
                mix, target = mix.to(device), target.to(device)
                
                # Validationì—ì„œë„ ë™ì¼í•˜ê²Œ ì ìš©
                with autocast(device_type='cuda', enabled=use_cuda):
                    mask = model(mix)
                    pred = mix * mask
                    loss = criterion(pred, target)
                
                val_loss += loss.item()
        
        avg_val_loss = val_loss / len(val_loader)
        
        print(f"Epoch {epoch+1} Result: Train Loss {avg_train_loss:.5f} | Val Loss {avg_val_loss:.5f}")

        # --- [Phase 3] Early Stopping Check (ìˆ˜ì •ë¨) ---
        early_stopping(avg_val_loss, model)
        
        if early_stopping.early_stop:
            # [í•µì‹¬] í˜„ì¬ Epochê°€ 50 ë¯¸ë§Œì´ë©´ ê°•ì œë¡œ ë©ˆì¶”ì§€ ì•Šê²Œ í•¨
            if epoch + 1 < 50:
                print(f"â³ ìµœì†Œ 50 Epoch ë³´ì¥ì„ ìœ„í•´ Early Stoppingì„ ë¯¸ë£¹ë‹ˆë‹¤. (í˜„ì¬: {epoch+1})")
                # ì¹´ìš´í„°ì™€ í”Œë˜ê·¸ë¥¼ ë¦¬ì…‹í•´ì„œ ê³„ì† í•™ìŠµí•˜ê²Œ ë§Œë“¦
                early_stopping.early_stop = False
                early_stopping.counter = 0
            else:
                print(f"ğŸ›‘ ì¡°ê¸° ì¢…ë£Œë¨! (Epoch {epoch+1})")
                print("ì„±ëŠ¥ì´ ë” ì´ìƒ ê°œì„ ë˜ì§€ ì•Šì•„ í•™ìŠµì„ ë©ˆì¶¥ë‹ˆë‹¤.")
                break
            
    print(f"í•™ìŠµ ì¢…ë£Œ. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ë¨: {best_model_path}")
    
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    # ê²½ë¡œ ê¸°ë³¸ê°’ ì„¤ì •ë¨
    parser.add_argument('--data_dir', type=str, default='D:\\musdb18hq\\train')
    parser.add_argument('--target', type=str, default='vocals')
    parser.add_argument('--epochs', type=int, default=1000)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--lr', type=float, default=0.001)
    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints')
    
    args = parser.parse_args()
    train(args)